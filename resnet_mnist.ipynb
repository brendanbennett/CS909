{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOmjxuLLnWU3WTMA2DewBxO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/foxtrotmike/CS909/blob/master/resnet_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simplified ResNet for MNIST Digit Recognition\n",
        "By [Fayyaz Minhas](https://sites.google.com/view/fayyaz/home)\n",
        "\n",
        "In this tutorial, we'll dive into the construction and understanding of a simplified ResNet (Residual Network) model tailored for recognizing digits in the MNIST dataset using PyTorch. The essence of ResNet lies in its innovative use of residual blocks that allow for training deeper neural networks by effectively addressing the vanishing gradient problem. Let's explore how to implement this powerful architecture step-by-step.\n",
        "\n",
        "## Setting the Stage\n",
        "First, we establish our working environment by importing necessary libraries and configuring our device. This step ensures that our model can leverage GPU acceleration if available:"
      ],
      "metadata": {
        "id": "cXor_mw_GHCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "jsP06JVMGXKI"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Data\n",
        "The MNIST dataset, consisting of 28x28 pixel grayscale images of handwritten digits, serves as our training and testing ground. We utilize PyTorch's torchvision package to load and transform the dataset into tensor format for our model. Data loaders are then employed to batch and shuffle our dataset, preparing it for the training and testing process."
      ],
      "metadata": {
        "id": "IXB4fOasGbqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)"
      ],
      "metadata": {
        "id": "OyrCFSKaGh08"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the Residual Block\n",
        "The heart of ResNet is the Residual Block. This component is designed to learn residual functions with reference to the layer inputs, allowing the network to have additional paths for gradient flow during backpropagation. his is achieved by introducing a shortcut (or skip connection) that bypasses one or more layers.\n",
        "\n",
        "### Components of a Residual Block\n",
        "Convolutional Layers: The main components of a residual block are its convolutional layers. Typically, a residual block contains two convolutional layers, each followed by a normalization layer. These layers are responsible for learning the weights from the input data. In the context of the MNIST example:\n",
        "\n",
        "* The first convolutional layer (conv1) applies a set of filters to the input. This is followed by batch normalization (bn1) to stabilize and speed up training.\n",
        "* The second convolutional layer (conv2) further processes the output of the first layer, followed by another batch normalization layer (bn2).\n",
        "* Batch Normalization (BN): Each convolutional layer is followed by a batch normalization layer. BN normalizes the output of a previous activation layer by subtracting the batch mean and dividing by the batch standard deviation. This ensures that the model trains faster and reduces the sensitivity to network initialization.\n",
        "* Activation Function: After each batch normalization layer, a non-linear activation function (ReLU, in this case) is applied. The ReLU (Rectified Linear Unit) function introduces non-linearity into the model, allowing it to learn more complex patterns in the data.\n",
        "* Skip Connection: The most critical feature of a residual block is the skip connection that adds the input of the residual block to its output. This mechanism (below) allows the gradient to be directly backpropagated to earlier layers. If the dimensions of the input and output of the residual block do not match, a downsampling layer (downsample) adjusts the dimensions of the input before it is added to the block's output. This is often accomplished with a convolutional layer with a kernel size of 1 (also known as a 1x1 convolution) in the skip connection."
      ],
      "metadata": {
        "id": "_UiAFsVEGnl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "if self.downsample:\n",
        "    residual = self.downsample(x)\n",
        "out += residual\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "dV73dw4GHqvJ",
        "outputId": "9b39cc1e-d5ed-4c95-ae0a-a77573d7070a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nif self.downsample:\\n    residual = self.downsample(x)\\nout += residual\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### How It Works\n",
        "The key idea behind a residual block is to learn the addition of some layers to the identity mapping of the input, rather than learning the entire transformation. This concept is encapsulated in the block's forward path:\n",
        "\n",
        "The input x is passed through two convolutional layers, each followed by batch normalization and ReLU activation.\n",
        "Simultaneously, the input x is also directly carried over through the skip connection. If necessary, it's transformed to match the dimensions.\n",
        "The output of the convolutional path and the skip connection path are added together.\n",
        "A final ReLU activation is applied to the combined output.\n",
        "This architecture allows the network to learn more efficiently. If additional layers do not improve the model, they can learn to approximate a zero function, effectively allowing the model to rely on the skip connection. Thus, even very deep networks can be trained without degradation, leading to significant improvements in various deep learning tasks.\n",
        "\n",
        "Here is the complete code"
      ],
      "metadata": {
        "id": "i9T8_FpdH0Y4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ZYp6cluZGm7E"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assembling the ResNet Model\n",
        "The step of assembling the ResNet model involves constructing a neural network architecture that incorporates multiple residual blocks, each designed to facilitate the training of deeper networks by allowing gradients to flow more freely during the backpropagation process. Here's a detailed breakdown of how the ResNet model is assembled, particularly focusing on the simplified version tailored for the MNIST dataset as described in the provided code.\n",
        "\n"
      ],
      "metadata": {
        "id": "JetbwcROH-g9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ResNet\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0], stride=1)\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # This line is changed to adaptively pool to 1x1 size\n",
        "        self.fc = nn.Linear(32, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "HXWVQfDKIjsq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initializing the ResNet Model\n",
        "The ResNet class extends nn.Module, PyTorch's base class for all neural network modules. The constructor of the ResNet class initializes the components that will be used in the network.\n",
        "\n",
        "* block: This parameter specifies the type of residual block to use within the network. In our case, it's the ResidualBlock class defined earlier.\n",
        "* layers: A list that specifies the number of residual blocks to be included in each layer of the network. For example, [2, 2] means there are two sections (or layers) in the network, each containing two residual blocks.\n",
        "* num_classes: The number of output classes. For MNIST, this is 10, corresponding to the digits 0 through 9.\n",
        "\n",
        "### Constructing the Initial Convolutional Layer\n",
        "Before the residual blocks, an initial convolutional layer processes the input images. This layer prepares the input for the residual blocks by applying a convolution that preserves the spatial dimensions (due to padding=1) and reduces the channel size from 1 (grayscale image) to 16. This is followed by batch normalization and ReLU activation.\n",
        "\n",
        "### Building Layers with Residual Blocks\n",
        "The core of the ResNet model is its layers of residual blocks. The make_layer method constructs these layers:\n",
        "\n",
        "* Each call to make_layer creates a sequence of residual blocks (blocks) with specified output channels (out_channels) and a stride that controls downsampling.\n",
        "* The first block in each sequence may include downsampling (stride != 1) to reduce the spatial dimensions of the feature maps, matching the ResNet architecture's design to decrease resolution while increasing depth.\n",
        "* If downsampling is required, a downsample convolutional layer adjusts the input's dimensions to enable element-wise addition with the block's output.\n",
        "\n",
        "### Adaptive Pooling and Output Layer\n",
        "After the residual blocks, an adaptive average pooling layer reduces each feature map to a single value, making the network's output size independent of the input size. This pooled output is then flattened and passed through a fully connected layer to produce the final class predictions. The output of this layer matches the number of classes in the dataset, providing the logits for each class.\n",
        "\n",
        "### Forward Pass\n",
        "The forward method defines the path of the input data through the network.\n",
        "It sequentially applies the initial convolutional layer, the residual layers, the adaptive pooling, and the fully connected layer.\n",
        "The skip connections within each residual block ensure that the input signal can bypass the convolutional operations, facilitating the training of deeper networks by improving gradient flow.\n",
        "\n",
        "## Training and Testing\n",
        "With our model defined, we proceed to train it on the MNIST dataset. During training, we monitor the loss at each epoch, adjusting the model parameters accordingly. The training loop is encapsulated as follows:"
      ],
      "metadata": {
        "id": "Qv0HvYf9InSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = ResNet(ResidualBlock, [2, 2], num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'resnet_model.ckpt')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kyy_0C7JeMx",
        "outputId": "43a50d43-36da-4694-e2f8-aff8707cc11e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.7457\n",
            "Epoch [1/5], Step [200/600], Loss: 0.2319\n",
            "Epoch [1/5], Step [300/600], Loss: 0.2321\n",
            "Epoch [1/5], Step [400/600], Loss: 0.1181\n",
            "Epoch [1/5], Step [500/600], Loss: 0.1656\n",
            "Epoch [1/5], Step [600/600], Loss: 0.1268\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0602\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0578\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0854\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0738\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0862\n",
            "Epoch [2/5], Step [600/600], Loss: 0.1333\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0799\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0346\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0621\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0748\n",
            "Epoch [3/5], Step [500/600], Loss: 0.1218\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0456\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0359\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0518\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0235\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0382\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0354\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0359\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0442\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0483\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0143\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0561\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0283\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0226\n",
            "Test Accuracy of the model on the 10000 test images: 98.95 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion\n",
        "By implementing a simplified ResNet architecture, we've created a robust model capable of high-accuracy digit recognition on the MNIST dataset. The incorporation of residual blocks demonstrates a significant advancement in deep learning, allowing us to train deeper networks more effectively. This tutorial not only highlights the practical application of ResNet but also underscores the importance of architectural innovations in enhancing model performance.\n",
        "\n",
        "Here is the complete code in a single block."
      ],
      "metadata": {
        "id": "3J04u7WzJntO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ov9phb5EdOY",
        "outputId": "b72e2a18-e162-4061-f763-5917cc73869f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.6256\n",
            "Epoch [1/5], Step [200/600], Loss: 0.2521\n",
            "Epoch [1/5], Step [300/600], Loss: 0.1570\n",
            "Epoch [1/5], Step [400/600], Loss: 0.2393\n",
            "Epoch [1/5], Step [500/600], Loss: 0.1080\n",
            "Epoch [1/5], Step [600/600], Loss: 0.1157\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0701\n",
            "Epoch [2/5], Step [200/600], Loss: 0.1114\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0491\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0185\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0881\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0315\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0377\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0598\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0303\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0234\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0731\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0512\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0527\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0272\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0251\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0806\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0345\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0681\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0390\n",
            "Epoch [5/5], Step [200/600], Loss: 0.0448\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0097\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0673\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0384\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0261\n",
            "Test Accuracy of the model on the 10000 test images: 98.71 %\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./data/',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n",
        "\n",
        "# Residual block\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
        "        super(ResidualBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.downsample = downsample\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        if self.downsample:\n",
        "            residual = self.downsample(x)\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "        return out\n",
        "\n",
        "# ResNet\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 16\n",
        "        self.conv = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(16)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.layer1 = self.make_layer(block, 16, layers[0], stride=1)\n",
        "        self.layer2 = self.make_layer(block, 32, layers[1], stride=2)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))  # This line is changed to adaptively pool to 1x1 size\n",
        "        self.fc = nn.Linear(32, num_classes)\n",
        "\n",
        "    def make_layer(self, block, out_channels, blocks, stride):\n",
        "        downsample = None\n",
        "        if (stride != 1) or (self.in_channels != out_channels):\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_channels))\n",
        "        layers = []\n",
        "        layers.append(block(self.in_channels, out_channels, stride, downsample))\n",
        "        self.in_channels = out_channels\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(out_channels, out_channels))\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.bn(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.avg_pool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out\n",
        "\n",
        "model = ResNet(ResidualBlock, [2, 2], num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
        "\n",
        "# Test the model\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
        "\n",
        "# Save the model checkpoint\n",
        "torch.save(model.state_dict(), 'resnet_model.ckpt')"
      ]
    }
  ]
}