{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNI6Z3k1Diy+HkGBXsmXBms",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/foxtrotmike/CS909/blob/master/cnn_mnist_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Building a Convolutional Neural Network with PyTorch\n",
        "By [Fayyaz Minhas](https://sites.google.com/view/fayyaz/home)\n",
        "\n",
        "\n",
        "Welcome to this tutorial on building a Convolutional Neural Network (CNN) using PyTorch for digit recognition on the MNIST dataset. This guide is designed to walk you through the process step-by-step, from setting up the dataset to training and evaluating the model. Whether you're new to deep learning or looking to refine your skills, this tutorial offers insights into the practical application of CNNs using one of the most popular deep learning frameworks.\n",
        "\n",
        "## Introduction to the MNIST Dataset\n",
        "The MNIST dataset is a classic in the field of machine learning, consisting of 70,000 grayscale images of handwritten digits (0 through 9). Each image is 28x28 pixels, and the task is to classify these images into the correct digit. It's widely used for benchmarking classification algorithms.\n",
        "\n",
        "## Setting Up the Environment\n",
        "We begin by importing necessary libraries and configuring the device to use for training. We'll use CUDA if available, allowing us to take advantage of GPU acceleration for faster training:"
      ],
      "metadata": {
        "id": "RimP3seg-vqI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
      ],
      "metadata": {
        "id": "ahUuOcM2_BX4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameters and Data Loading\n",
        "Next, we define our hyperparameters and load the MNIST dataset. PyTorch's torchvision module makes it easy to download and load the MNIST dataset with minimal effort. We also set up data loaders for batching and shuffling:"
      ],
      "metadata": {
        "id": "O6uLrBt5_D3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sFzy9dNm98Wl"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hyper parameters\n",
        "num_epochs = 5\n",
        "num_classes = 10\n",
        "batch_size = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                           train=True,\n",
        "                                           transform=transforms.ToTensor(),\n",
        "                                           download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='../../data/',\n",
        "                                          train=False,\n",
        "                                          transform=transforms.ToTensor())\n",
        "\n",
        "# Data loader\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the CNN Model\n",
        "Our CNN model consists of two convolutional layers, each followed by batch normalization, a ReLU activation function, and max pooling. The output is then passed through a fully connected layer to produce the class scores:"
      ],
      "metadata": {
        "id": "Xhm2yYL-_X8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Convolutional neural network (two convolutional layers)\n",
        "class ConvNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(ConvNet, self).__init__()\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
        "        self.fc = nn.Linear(7*7*32, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "5N-hlLBs_Vov"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model\n",
        "We train the model using a loop that iterates over our dataset for a given number of epochs. In each epoch, we perform a forward pass, calculate the loss, and update the model's weights with backpropagation:"
      ],
      "metadata": {
        "id": "UJz05kF8_isF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = ConvNet(num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train the model\n",
        "total_step = len(train_loader)\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wCOLI-Jo_qWk",
        "outputId": "6075fbb4-b3d2-4231-ae0b-7e5a13f45020"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/600], Loss: 0.1787\n",
            "Epoch [1/5], Step [200/600], Loss: 0.0467\n",
            "Epoch [1/5], Step [300/600], Loss: 0.0438\n",
            "Epoch [1/5], Step [400/600], Loss: 0.0407\n",
            "Epoch [1/5], Step [500/600], Loss: 0.0503\n",
            "Epoch [1/5], Step [600/600], Loss: 0.0244\n",
            "Epoch [2/5], Step [100/600], Loss: 0.0873\n",
            "Epoch [2/5], Step [200/600], Loss: 0.0356\n",
            "Epoch [2/5], Step [300/600], Loss: 0.0932\n",
            "Epoch [2/5], Step [400/600], Loss: 0.0513\n",
            "Epoch [2/5], Step [500/600], Loss: 0.0082\n",
            "Epoch [2/5], Step [600/600], Loss: 0.0419\n",
            "Epoch [3/5], Step [100/600], Loss: 0.0214\n",
            "Epoch [3/5], Step [200/600], Loss: 0.0982\n",
            "Epoch [3/5], Step [300/600], Loss: 0.0070\n",
            "Epoch [3/5], Step [400/600], Loss: 0.0071\n",
            "Epoch [3/5], Step [500/600], Loss: 0.0686\n",
            "Epoch [3/5], Step [600/600], Loss: 0.0443\n",
            "Epoch [4/5], Step [100/600], Loss: 0.0115\n",
            "Epoch [4/5], Step [200/600], Loss: 0.0046\n",
            "Epoch [4/5], Step [300/600], Loss: 0.0188\n",
            "Epoch [4/5], Step [400/600], Loss: 0.0160\n",
            "Epoch [4/5], Step [500/600], Loss: 0.0250\n",
            "Epoch [4/5], Step [600/600], Loss: 0.0359\n",
            "Epoch [5/5], Step [100/600], Loss: 0.0137\n",
            "Epoch [5/5], Step [200/600], Loss: 0.1007\n",
            "Epoch [5/5], Step [300/600], Loss: 0.0064\n",
            "Epoch [5/5], Step [400/600], Loss: 0.0131\n",
            "Epoch [5/5], Step [500/600], Loss: 0.0081\n",
            "Epoch [5/5], Step [600/600], Loss: 0.0747\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the Model\n",
        "After training, we evaluate the model's performance on the test set to calculate its accuracy:"
      ],
      "metadata": {
        "id": "--l0_qaO_keL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1h_fYDM_xrH",
        "outputId": "e43452a9-aeb6-481d-b575-ce94ad8d8d79"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy of the model on the 10000 test images: 98.92 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the Model\n",
        "Finally, we save the trained model for future use:"
      ],
      "metadata": {
        "id": "gpmpRnQU_1jm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'model.ckpt')\n"
      ],
      "metadata": {
        "id": "IWNT6JyM_5v1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This tutorial has guided you through the process of building, training, and evaluating a CNN with PyTorch on the MNIST dataset. With this foundation, you're well-equipped to tackle more complex image classification tasks and explore deeper CNN architectures.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JvgxgwdE_6AM"
      }
    }
  ]
}